  <div class="row">
    <h2>Projects</h2>

<!--     <hr>
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">Counting Bicyclists in Tempe city (with Semi-supervised Reidentification) <a target="_blank" href="https://sandcastle.cesium.com/standalone.html#c=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">[3D map]</a> <em style="font-size: 50%;"> [Ongoing]</em></h3>
        <br>
        <p>Average cost of a market-available 'smart' bike counters is around $2500-$4500. This makes it prohibitively expensive for a city to deploy them on a large number of streets. So, I am developing a system that is an interesting mix of new camera hardware and computer vision-based algorithms to count bicyclists in the city of Tempe, Arizona. *This project is still going on but the preliminary analysis indicates cost savings of about 15-20 times.</p>
      </div>
    </div> -->

    <hr>
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">Graph-P&IDs</a> <em style="font-size: 50%;"> [Ongoing]</em></h3>
        <br>
        <p>Converting P&IDs into a graph data structure to support NLP queries, information retrieval, safety compliance, and drawing editing.
        </p>
      </div>
    </div>

    <hr>
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">Semi-supervised symbols detection in Piping and Instrumentation Drawings (P&IDs)<a target="_blank" href="https://www.sciencedirect.com/science/article/abs/pii/S0926580523005204"><em style="font-size: 50%;">[Paper]</a></em></h3>
        <br>
      </p>
      <a class="github-button btn" href="https://github.com/mgupta70/PID_Symbol_Detection" data-size="large" data-show-count="false"
        aria-label="mgupta70/PID_Symbol_Detection on GitHub">Code</a>
      <a class="github-button" href="https://github.com/mgupta70/PID_Symbol_Detection" data-icon="octicon-star" data-size="large"
        data-show-count="true" aria-label="Star mgupta70/PID_Symbol_Detection on GitHub">Star</a>
        <figure>
          <img src="https://github.com/mgupta70/PID_Symbol_Detection/blob/main/media/workflow.svg" width="300px">
          <figcaption>P&ID overview</figcaption>
        </figure>
        <p>Typically, P&IDs would have 100's of symbols depicting equipments like valves, compressors, piping components, etc. Manually labelling the dataset is a challenging task due to (i) large number of classesm (ii) many symbols resemble a lot with one another causing confusion while annotating and (iii) non-standardized drawing layouts. Hence, a symbol detection pipleline with class agnostic detection & self-supervised symbol classification is proposed that achieved a Top-5 accuracy of 95.49% over 102 test classes.</p>
      </div>
    </div>


    <hr>
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">3D scene reconstruction with NeRF and SfM from 360Â°camera images<a target="_blank" href="https://drive.google.com/file/d/1Mc4nvLkxQQfcEw4aE41MP5FPK6P2ftfT/view?usp=drive_link"><em style="font-size: 50%;">[Paper]</a></em></h3>
        <br>
        <p> Capturing a scene with Lidar inherently needs a large amount of data storage. So, in this study, I investigated an alternative approach to capture the 3D information via 360 videos. I particularly used Structure-from-Motion (SfM) and Neural Radiance Fields (NeRF) for the task of 3D reconstruction. These techniques provide significant savings in terms of data storage requirements but there is a trade-off with dimensional accuracy. Please refer the Results section in the attached paper for quantitative results. 
          Since construction sites are not always well-lit, NeRF didn't perform quite well for the objects that were far and poorly lit. However, areas which are well-lit, 3D reconstruction by NeRF and SfM were almost same.
          In my view, the selection of appropriate technology would be driven by its use case. For ex: for a simple task of visualization, SfM method could be preferred but if one needs precise measurement (of tiny or thin objects) then Lidar would be the choice.</p>
      </div>
    </div>
    <div class="row" align="center">
  <div class="col-sm-4">
    <figure>
      <img src="static/img/small_scan.gif" width="300px">
      <figcaption>Laser scan</figcaption>
    </figure>
  </div>
  <div class="col-sm-4">
    <figure>
      <img src="static/img/small_nerf.gif" width="300px">
      <figcaption>NeRF</figcaption>
    </figure>
  </div>
  <div class="col-sm-4">
    <figure>
      <img src="static/img/small_colmap.gif" width="300px">
      <figcaption>SfM</figcaption>
    </figure>
  </div>
</div>

    
    <hr>
     <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">Automated 2D building plans to 3D digital model<em style="font-size: 50%;"> [<a target = "_blank" href = "https://www.researchgate.net/publication/373921858_Interoperability_between_Deep_Neural_Networks_and_3D_Architectural_Modeling_Software_Affordances_of_Detection_and_Segmentation">Journal paper</a>; <a target="_blank" href="https://doi.org/10.22260/ISARC2022/0023"> Conf paper</a>] </em></h3>
        <br>
        <p>  Aim of this project is to speed up the conversion of a 2D CAD into a 3D BIM model. We found that the semantic segmentation-based approach is more performant than the typical bounding-based methods. In post-processing, we configured the linkage of neural network outputs to a 3D drafting software via Dynamo API.</p>
        
      </div>
    </div>


    <hr>
     <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">Valve detection in P&IDs without human annotations: A synthetic data approach<em style="font-size: 50%;"><a target="_blank" href="https://doi.org/10.22260/ISARC2022/0088"> [Conf paper]</a></em></h3>
        <br>
        <p>Devised a synthetic data generation pipeline to create a labeled dataset without any human annotations. Experimentation revealed that the presence of look-alike symbols (i.e. hard negatives) helped in reducing false positives & increased the performance.</p>
        


</div>
     
