  <div class="row">
    <h2>Projects</h2>


    <hr>
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">Graph-P&IDs</a> <em style="font-size: 50%;"> [Ongoing]</em></h3>
        <br>
        <p>Converting P&IDs into a graph data structure to support NLP queries, information retrieval, safety compliance, and drawing editing.
          Will be updated soon ...
        </p>
      </div>
    </div>

    <hr>
    <div class="row">
     <div class="col-sm-12">
       <h3 class="content_heading">Condition Assessment - Monitoring Vibrations in a Hydro-Electric Dam </h3>
       <img src="https://img.shields.io/badge/Digital%20Twins-cyan" alt="DT Badge">
       <img src="https://img.shields.io/badge/Predictive%20Maintenance-grey" alt="PdM Badge">
       <img src="https://img.shields.io/badge/Anomaly%20Detection-green" alt="AD Badge">
       <img src="https://img.shields.io/badge/Recurrent%20Neural%20Network-orange" alt="RNN Badge">
       <img src="https://img.shields.io/badge/Performance%20Curve%20Modeling-blue" alt="PCM Badge">
       <br>
       <br>
       <a class="github-button btn" href="https://github.com/mgupta70/Predictive-Maintenance-Data-Analytics-App" data-size="large" data-show-count="false"
        aria-label="mgupta70/Predictive-Maintenance-Data-Analytics-App on GitHub">Code</a>
      <a class="github-button" href="https://github.com/mgupta70/Predictive-Maintenance-Data-Analytics-App" data-icon="octicon-star" data-size="large"
        data-show-count="true" aria-label="Star mgupta70/Predictive-Maintenance-Data-Analytics-App on GitHub">Star</a>
        <br>
        <figure>
        <img src="static/img/app_overview_svg.svg" width="750px">
      </figure>
      <br>
       <p><strong><mark>Link to Webapp</mark></strong> -
         <a target="_blank" href="https://predictive-maintenance-time-series.streamlit.app/">[Condition Monitoring App]</a>,
       </p>
       <br>
       <p> Developed anomaly detection & time-series forecasting models to monitor vibrations in dam turbines for the safe operation. 
        The project is aimed to shift from costly reactive/preventive maintenance to more efficient predicitive maintenance using the operational history of the asset.
        However, the biggest challenge was the absence of 'faulty' vibration data as most of the time, turbine was operated in normal (safe) working condition.
        To solve this, I engaged with field engineers to understand the data and integrate domain knowledge to buid a model for estimating <del> vibration at any time t in future</del> <b>rate of change of vibration</b>. </p>
       
     </div>
   </div>

    <hr>
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">Semi-supervised symbols detection in Piping and Instrumentation Drawings (P&IDs)</h3>
        <img src="https://img.shields.io/badge/Resnet-grey" alt="Resnet Badge">
        <img src="https://img.shields.io/badge/Yolov8-orange" alt="Yolov8 Badge">
        <img src="https://img.shields.io/badge/Siamese%20networks-indigo" alt="SiameseNetwork Badge">
        <img src="https://img.shields.io/badge/Self%20Supervised%20Learning-green" alt="SelfSupervised Badge">
        <br>
        <br>

      <a class="github-button btn" href="https://github.com/mgupta70/PID_Symbol_Detection" data-size="large" data-show-count="false"
        aria-label="mgupta70/PID_Symbol_Detection on GitHub">Code</a>
      <a class="github-button" href="https://github.com/mgupta70/PID_Symbol_Detection" data-icon="octicon-star" data-size="large"
        data-show-count="true" aria-label="Star mgupta70/PID_Symbol_Detection on GitHub">Star</a>
        <figure>
          <img src="static/img/workflow.svg">
        </figure>
        <br>
        <p><strong><mark>Published Papers </mark></strong>-
          <a target="_blank" href="https://www.sciencedirect.com/science/article/abs/pii/S0926580523005204">[Paper-1]</a>,
          <a target="_blank" href="https://doi.org/10.22260/ISARC2022/0088"> [Paper-2]</a>
        </p>
        </p>
        <br>
        <p>Typically, P&IDs would have 100's of symbols depicting equipments like valves, compressors, piping components, etc. Manually labelling the dataset is a challenging task due to (i) large number of classes, (ii) many symbols resemble a lot with one another causing confusion while annotating and (iii) non-standardized drawing layouts. Hence, a symbol detection pipleline with class agnostic detection & self-supervised symbol classification is proposed that achieved a Top-5 accuracy of 95.49% over 102 test classes.</p>
      </div>
    </div>


    <hr>
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">3D scene reconstruction with NeRF and SfM from 360Â°camera images</h3>
        <img src="https://img.shields.io/badge/NerfStudio-yellow" alt="Nerf Badge">
        <img src="https://img.shields.io/badge/Colmap-orange" alt="Colmap Badge">
        <img src="https://img.shields.io/badge/Cloud%20Compare-blue" alt="CloudCompare Badge">
        <img src="https://img.shields.io/badge/Keypoint%20Matching-green" alt="Keypoint Badge">
        <br>
        <br>
        <p><strong><mark>Published Paper</mark></strong> -
          <a target="_blank" href="https://drive.google.com/file/d/1Mc4nvLkxQQfcEw4aE41MP5FPK6P2ftfT/view?usp=drive_link">[Paper]</a>
        </p>
        <p> Capturing a scene with Lidar inherently needs a large amount of data storage. So, in this study, I investigated an alternative approach to capture the 3D information via 360 videos. I particularly used Structure-from-Motion (SfM) and Neural Radiance Fields (NeRF) for the task of 3D reconstruction. These techniques provide significant savings in terms of data storage requirements but there is a trade-off with dimensional accuracy. Please refer the Results section in the attached paper for quantitative results. 
          Since construction sites are not always well-lit, NeRF didn't perform quite well for the objects that were far and poorly lit. However, areas which are well-lit, 3D reconstruction by NeRF and SfM were almost same.
          In my view, the selection of appropriate technology would be driven by its use case. For ex: for a simple task of visualization, SfM method could be preferred but if one needs precise measurement (of tiny or thin objects) then Lidar would be the choice.</p>
      </div>
    </div>
    <div class="row" align="center">
  <div class="col-sm-4">
    <figure>
      <img src="static/img/small_scan.gif" width="300px">
      <figcaption>Laser scan</figcaption>
    </figure>
  </div>
  <div class="col-sm-4">
    <figure>
      <img src="static/img/small_nerf.gif" width="300px">
      <figcaption>NeRF</figcaption>
    </figure>
  </div>
  <div class="col-sm-4">
    <figure>
      <img src="static/img/small_colmap.gif" width="300px">
      <figcaption>SfM</figcaption>
    </figure>
  </div>
</div>

<hr>
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">Sleep Posture Correction to Alleviate Snoring</h3>
        <img src="https://img.shields.io/badge/Spectrogram-grey" alt="Spectrogram Badge">
        <img src="https://img.shields.io/badge/Arduino%20Nano%20BLE%20Sense-blue" alt="BLE Badge">
        <img src="https://img.shields.io/badge/Embedded%20Machine%20Learning-orange" alt="EML Badge">
        <img src="https://img.shields.io/badge/Relay-green" alt="Relay Badge">
        <img src="https://img.shields.io/badge/Mini%20Compressor-indigo" alt="MC Badge">
        <br>
        <br>
      <a class="github-button btn" href="https://github.com/mgupta70/Embedded-ML-Snoring-Relief-Pillow" data-size="large" data-show-count="false"
        aria-label="mgupta70/Embedded-ML-Snoring-Relief-Pillow on GitHub">Code</a>
        <br>
        <br>
        <p> Integrated smart sensing into a Pillow by connecting it with an air compressor to adjust person's  position, once snoring is detected. 
          Snoring detection is performed by image classification of audio signals converted into spectrogram. Model is light-weight and runs on Arduino Nano 33 BLE, embedded in the pillow. 
        </p>
      </div>
    </div>

    <div style="display: flex; justify-content: space-between;">
      <figure>
        <img src="static/img/Components.png" alt="Components" width="300">
        <figcaption>Components</figcaption>
      </figure>
    
      <figure>
        <img src="static/img/circuit_design.png" alt="Circuit Design" width="300">
        <figcaption>Circuit Design</figcaption>
      </figure>
    
      <figure>
        <img src="static/img/Setup.png" alt="Setup" width="300">
        <figcaption>Setup</figcaption>
      </figure>
    </div>
</div>

    
    <hr>
     <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">Automated 3D digital models from 2D CAD plans</h3>
        <img src="https://img.shields.io/badge/Faster%20RCNN-pink" alt="RCNN Badge">
        <img src="https://img.shields.io/badge/Yolov4-orange" alt="Yolov4 Badge">
        <img src="https://img.shields.io/badge/Dynamo%20API-green" alt="Dynamo Badge">
        <img src="https://img.shields.io/badge/Autodesk-blue" alt="Autodesk Badge">
        <br>
        <br>
        <p><strong><mark>Published Papers</mark></strong> -
          <a target="_blank" href="https://www.mdpi.com/2075-5309/13/9/2336">[Paper-1]</a>,
          <a target="_blank" href="https://www.iaarc.org/publications/2022_proceedings_of_the_39th_isarc_bogota_colombia/automated_wall_detection_in_2d_cad_drawings_to_create_digital_3d_models.html"> [Paper-2]</a>
        </p>
        <br>
        <p>  Aim of this project is to speed up the conversion of a 2D CAD into a 3D BIM model. We found that the semantic segmentation-based approach is more performant than the typical bounding-based methods. In post-processing, we configured the linkage of neural network outputs to a 3D drafting software via Dynamo API.</p>
        
      </div>
    </div>


</div>
     
