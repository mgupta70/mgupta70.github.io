  <div class="row">
    <h2>Projects</h2>


    <hr>
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">Visual document parsing for engineering blueprints</em></h3>
        <br>
        <p><b>Context:</b> Information Extraction from Engineering Drawings (like P&IDs) is challenging because of 2 reasons. (1) They are often shared in image-based formats (e.g., PDF, PNG, JPEG) rendering CAD software tools unable to index the information. (2) A lot of information in Engineering Drawings is 'visual' in nature which requires domain expertise and topological understanding to understand how different objects are functionally connected to one another.<br>
        <b>Solution:</b> To solve the challenge of information extraction, this work attempts to <b>make the 'visual' information searchable</b> within P&IDs using LLMs and Computer Vision. Consequently, P&IDs are first digitized by identifying entities such as symbols, lines, and text (Step-<b>I</b>). The detected entities are then linked to create a base entity graph (Step-<b>II</b>). Here, symbols = nodes, lines = edges, texts = property. The base entity graph is then augmented with semantic attributes for nodes and edges forming knowledge graph (Step-<b>III</b>). The knowledge graph is then used to answer queries such as "find all the valves in the drawing" or perform design checks like "are pumps provided with strainers to prevent dirt getting in? (Step-<b>IV</b>)".<br>
		  <br>
        <figure>
        <img src="static/img/pid_overview.png" width="1150px">
      </figure>
        </p>
        <p><b>Symbol Detection:</b> Symbols are detected using Class-Agnostic Detection followed by one-shot classification. This is done because in P&IDs (a type of EDs), there can be more than 400 different types of symbols. Annotating all symbol categories will be time-consuming process. Training in class-agnostic manner will help building a more 'generalizable' symbol detector with capabilites of detecting unseen symbol classes with approx 65% savings in resources to annotate dataset. Refer [Paper] for more details and results<br>
        <b>Line Detection:</b> (Most tricky) Developed a custom method using Probabilistic Hough Transform with line-merging and programmatic hyperparameter selection modules. Our method could find all lines in a 7000x4561 image within 22 seconds with no manual intervention (compared to few minutes in pixel-by-pixel traversal). [Paper] (Accepted) posting soon....<br>
        <b>Text Detection:</b> Text is detected by finetuning KerasOCR. The text is then linked to a symbol or line using regular expression-based matching.<br>
        <b>Knowledge Graph:</b> The knowledge graph is built using Neo4j. The graph is then queried using Cypher query language. [Paper] (Accepted) posting soon....<br>
        </p>
      </div>
    </div>

    <hr>
    <div class="row">
     <div class="col-sm-12">
       <h3 class="content_heading">Condition Assessment - Monitoring Vibrations in a Hydro-Electric Dam </h3>
       <img src="https://img.shields.io/badge/Digital%20Twins-cyan" alt="DT Badge">
       <img src="https://img.shields.io/badge/Predictive%20Maintenance-grey" alt="PdM Badge">
       <img src="https://img.shields.io/badge/Anomaly%20Detection-green" alt="AD Badge">
       <img src="https://img.shields.io/badge/Recurrent%20Neural%20Network-orange" alt="RNN Badge">
       <img src="https://img.shields.io/badge/Performance%20Curve%20Modeling-blue" alt="PCM Badge">
       <br>
       <br>
       <a class="github-button btn" href="https://github.com/mgupta70/Predictive-Maintenance-Data-Analytics-App" data-size="large" data-show-count="false"
        aria-label="mgupta70/Predictive-Maintenance-Data-Analytics-App on GitHub">Code</a>
      <a class="github-button" href="https://github.com/mgupta70/Predictive-Maintenance-Data-Analytics-App" data-icon="octicon-star" data-size="large"
        data-show-count="true" aria-label="Star mgupta70/Predictive-Maintenance-Data-Analytics-App on GitHub">Star</a>
        <br>
        <figure>
        <img src="static/img/app_overview_svg.svg" width="750px">
      </figure>
      <br>
       <p><strong><mark>Link to Webapp</mark></strong> -
         <a target="_blank" href="https://predictive-maintenance-time-series.streamlit.app/">[Condition Monitoring App]</a>,
       </p>
       <br>
       <p><b>Context:</b> The project is part of a larger initiative to develop a digital twin of the dam. The digital twin will be used to monitor the health of the dam and its components, enabling predictive maintenance and reducing downtime.<br> 
        <b>Challenge:</b> The biggest challenge was the absence of 'faulty' vibration data as most of the time, turbine was operated in normal (safe) working condition.
        <b>Solution:</b> To solve this, I engaged with field engineers to understand the data and integrate domain knowledge to buid a model for estimating <del> vibration at any time t in future</del> <b>rate of change of vibration</b>. Developed a web application that allows users to visualize the data and perform anomaly detection and time-series forecasting. The app uses a custom ANN-LSTM to predict the future values of the vibration data, and a performance curve model to detect anomalies. The app also includes a dashboard that displays the current status of the dam and its components, as well as alerts for any anomalies detected. </p>
       
     </div>
   </div>


    <hr>
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">3D scene reconstruction with NeRF and SfM from 360Â°camera images</h3>
        <img src="https://img.shields.io/badge/NerfStudio-yellow" alt="Nerf Badge">
        <img src="https://img.shields.io/badge/Colmap-orange" alt="Colmap Badge">
        <img src="https://img.shields.io/badge/Cloud%20Compare-blue" alt="CloudCompare Badge">
        <img src="https://img.shields.io/badge/Keypoint%20Matching-green" alt="Keypoint Badge">
        <br>
        <br>
        <p><strong><mark>Published Paper</mark></strong> -
          <a target="_blank" href="https://drive.google.com/file/d/1Mc4nvLkxQQfcEw4aE41MP5FPK6P2ftfT/view?usp=drive_link">[Paper]</a>
        </p>
        <p> Capturing a scene with Lidar inherently needs a large amount of data storage. So, in this study, I investigated an alternative approach to capture the 3D information via 360 videos. I particularly used Structure-from-Motion (SfM) and Neural Radiance Fields (NeRF) for the task of 3D reconstruction. These techniques provide significant savings in terms of data storage requirements but there is a trade-off with dimensional accuracy. Please refer the Results section in the attached paper for quantitative results. 
          Since construction sites are not always well-lit, NeRF didn't perform quite well for the objects that were far and poorly lit. However, areas which are well-lit, 3D reconstruction by NeRF and SfM were almost same.
          In my view, the selection of appropriate technology would be driven by its use case. For ex: for a simple task of visualization, SfM method could be preferred but if one needs precise measurement (of tiny or thin objects) then Lidar would be the choice.</p>
      </div>
    </div>
    <div class="row" align="center">
  <div class="col-sm-4">
    <figure>
      <img src="static/img/small_scan.gif" width="300px">
      <figcaption>Laser scan</figcaption>
    </figure>
  </div>
  <div class="col-sm-4">
    <figure>
      <img src="static/img/small_nerf.gif" width="300px">
      <figcaption>NeRF</figcaption>
    </figure>
  </div>
  <div class="col-sm-4">
    <figure>
      <img src="static/img/small_colmap.gif" width="300px">
      <figcaption>SfM</figcaption>
    </figure>
  </div>
</div>

<hr>
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">Sleep Posture Correction to Alleviate Snoring</h3>
        <img src="https://img.shields.io/badge/Spectrogram-grey" alt="Spectrogram Badge">
        <img src="https://img.shields.io/badge/Arduino%20Nano%20BLE%20Sense-blue" alt="BLE Badge">
        <img src="https://img.shields.io/badge/Embedded%20Machine%20Learning-orange" alt="EML Badge">
        <img src="https://img.shields.io/badge/Relay-green" alt="Relay Badge">
        <img src="https://img.shields.io/badge/Mini%20Compressor-indigo" alt="MC Badge">
        <br>
        <br>
      <a class="github-button btn" href="https://github.com/mgupta70/Embedded-ML-Snoring-Relief-Pillow" data-size="large" data-show-count="false"
        aria-label="mgupta70/Embedded-ML-Snoring-Relief-Pillow on GitHub">Code</a>
        <br>
        <br>
        <p> Integrated smart sensing into a Pillow by connecting it with an air compressor to adjust person's  position, once snoring is detected. 
          Snoring detection is performed by image classification of audio signals converted into spectrogram. Model is light-weight and runs on Arduino Nano 33 BLE, embedded in the pillow. 
        </p>
      </div>
    </div>

    <div style="display: flex; justify-content: space-between;">
      <figure>
        <img src="static/img/Components.png" alt="Components" width="300">
        <figcaption>Components</figcaption>
      </figure>
    
      <figure>
        <img src="static/img/circuit_design.png" alt="Circuit Design" width="300">
        <figcaption>Circuit Design</figcaption>
      </figure>
    
      <figure>
        <img src="static/img/Setup.png" alt="Setup" width="300">
        <figcaption>Setup</figcaption>
      </figure>
    </div>
</div>

    
    <hr>
     <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading">Automated 3D digital models from 2D CAD plans</h3>
        <img src="https://img.shields.io/badge/Faster%20RCNN-pink" alt="RCNN Badge">
        <img src="https://img.shields.io/badge/Yolov4-orange" alt="Yolov4 Badge">
        <img src="https://img.shields.io/badge/Dynamo%20API-green" alt="Dynamo Badge">
        <img src="https://img.shields.io/badge/Autodesk-blue" alt="Autodesk Badge">
        <br>
        <br>
        <p><strong><mark>Published Papers</mark></strong> -
          <a target="_blank" href="https://www.mdpi.com/2075-5309/13/9/2336">[Paper-1]</a>,
          <a target="_blank" href="https://www.iaarc.org/publications/2022_proceedings_of_the_39th_isarc_bogota_colombia/automated_wall_detection_in_2d_cad_drawings_to_create_digital_3d_models.html"> [Paper-2]</a>
        </p>
        <br>
        <p>  Aim of this project is to speed up the conversion of a 2D CAD into a 3D BIM model. We found that the semantic segmentation-based approach is more performant than the typical bounding-based methods. In post-processing, we configured the linkage of neural network outputs to a 3D drafting software via Dynamo API.</p>
        <figure>
          <img src="static/img/cad_to_3d.png" alt="wall3d" width="800">
        </figure>
        
      </div>
    </div>


</div>
     
